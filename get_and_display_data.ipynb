{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bae2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06-06-2025 14:09:23] [pypickle.pypickle] [INFO] Loading Pickle file: [test_ddos_df.pkl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1084, 130)\n",
      "created mitm feature vectors for mitm in 1.1589179039001465s, rows: 7\n",
      "created mitm feature vectors for mitm in 1.0830488204956055s, rows: 11\n",
      "created mitm feature vectors for mitm in 1.9867689609527588s, rows: 18\n",
      "created mitm feature vectors for mitm in 1.3071486949920654s, rows: 24\n",
      "created mitm feature vectors for mitm in 2.673678159713745s, rows: 30\n",
      "created mitm feature vectors for mitm in 8.94458270072937s, rows: 37\n",
      "created mitm feature vectors for mitm in 9.849808931350708s, rows: 42\n",
      "created mitm feature vectors for mitm in 3.3192477226257324s, rows: 46\n",
      "created mitm feature vectors for mitm in 7.654247283935547s, rows: 51\n",
      "created mitm feature vectors for mitm in 4.584762334823608s, rows: 55\n",
      "created mitm feature vectors for mitm in 2.0147202014923096s, rows: 59\n",
      "created mitm feature vectors for mitm in 2.4382259845733643s, rows: 65\n",
      "created mitm feature vectors for mitm in 6.654208421707153s, rows: 72\n",
      "created mitm feature vectors for mitm in 4.647281169891357s, rows: 77\n",
      "created mitm feature vectors for mitm in 2.124854564666748s, rows: 80\n",
      "created mitm feature vectors for mitm in 1.0299646854400635s, rows: 87\n",
      "created mitm feature vectors for mitm in 1.146836519241333s, rows: 94\n",
      "created mitm feature vectors for mitm in 2.6494147777557373s, rows: 98\n",
      "created mitm feature vectors for mitm in 8.494451761245728s, rows: 104\n",
      "created mitm feature vectors for mitm in 21.10890817642212s, rows: 113\n",
      "created mitm feature vectors for mitm in 10.645507574081421s, rows: 120\n",
      "created mitm feature vectors for mitm in 4.561509370803833s, rows: 128\n",
      "created mitm feature vectors for mitm in 5.1973183155059814s, rows: 134\n",
      "created mitm feature vectors for mitm in 5.694844961166382s, rows: 140\n",
      "created mitm feature vectors for mitm in 5.163653612136841s, rows: 144\n",
      "created mitm feature vectors for mitm in 2.088723659515381s, rows: 148\n",
      "created mitm feature vectors for mitm in 2.281806230545044s, rows: 151\n",
      "created mitm feature vectors for mitm in 2.1908528804779053s, rows: 156\n",
      "created mitm feature vectors for mitm in 3.348316192626953s, rows: 162\n",
      "created mitm feature vectors for mitm in 2.059762716293335s, rows: 167\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, tsw_object \u001b[38;5;129;01min\u001b[39;00m tsw_paths[tsw_paths[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mmitm\u001b[39m\u001b[33m'\u001b[39m].iterrows():\n\u001b[32m     39\u001b[39m     start = dp.time.time()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     tsw = \u001b[43mdp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mThirtySecondWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtsw_object\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     mitm_local_feature_vectors = dl.create_feature_vectors(tsw, valid_columns)\n\u001b[32m     42\u001b[39m     mitm_local_feature_vectors[\u001b[33m'\u001b[39m\u001b[33mattack_type\u001b[39m\u001b[33m'\u001b[39m] = tsw_object[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;66;03m# add attack type column for training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/HSP_IDS/data_analysis/data_processing.py:101\u001b[39m, in \u001b[36mThirtySecondWindow.__init__\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mself\u001b[39m.s1 = \u001b[38;5;28mself\u001b[39m.get_s1(path.joinpath(\u001b[33m'\u001b[39m\u001b[33ms1_general_qs.csv\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    100\u001b[39m \u001b[38;5;28mself\u001b[39m.connection_feature_names = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mconnection_features.CSV\u001b[39m\u001b[33m'\u001b[39m).columns\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28mself\u001b[39m.hosts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_hosts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/HSP_IDS/data_analysis/data_processing.py:113\u001b[39m, in \u001b[36mThirtySecondWindow.get_hosts\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    110\u001b[39m     entry_path = path / entry\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m entry_path.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         hosts.append(\u001b[43mHost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection_feature_names\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hosts\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/HSP_IDS/data_analysis/data_processing.py:59\u001b[39m, in \u001b[36mHost.__init__\u001b[39m\u001b[34m(self, path, names)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.s3 = \u001b[38;5;28mself\u001b[39m.get_s3(path / \u001b[33m'\u001b[39m\u001b[33ms3_connection_qs.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m#self.ten_second_windows = self.get_ten_second_windows(path)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28mself\u001b[39m.connections : defaultdict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/HSP_IDS/data_analysis/data_processing.py:90\u001b[39m, in \u001b[36mHost.get_connections\u001b[39m\u001b[34m(self, path, names)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m#if ten_second_window_path.is_dir(): # is_dir() is slow\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, connection \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(os.scandir(ten_second_window_path)):\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     connection_path = \u001b[43mten_second_window_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m#if connection_path.is_dir():\u001b[39;00m\n\u001b[32m     93\u001b[39m     connections[connection.name] = pd.concat([connections[connection.name], pd.read_csv(connection_path / \u001b[33m'\u001b[39m\u001b[33mhost_data_chunk_full.csv\u001b[39m\u001b[33m'\u001b[39m)]) \u001b[38;5;66;03m# use connection.name, otherwise it doesn't count as same key!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/Miniconda/envs/jannis_env/lib/python3.11/pathlib.py:765\u001b[39m, in \u001b[36mPurePath.__truediv__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Combine this path with one or several arguments, and return a\u001b[39;00m\n\u001b[32m    759\u001b[39m \u001b[33;03m    new path representing either a subpath (if all arguments are relative\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[33;03m    paths) or a totally different path (if one of the arguments is\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[33;03m    anchored).\u001b[39;00m\n\u001b[32m    762\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child(args)\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m    766\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    767\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child((key,))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import data_analysis.data_processing as dp\n",
    "import data_analysis.data_learning as dl\n",
    "\n",
    "# reload module to bypass caching\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "importlib.reload(dl)\n",
    "\n",
    "# paths\n",
    "test_window_path_home = dp.Path(r'\\\\?\\C:\\Users\\jannis\\Documents\\HSP_IDS\\Material\\Aktuell\\2025-02-17_11-14-33_192.168.1.0-normal_1\\1554220324.748197-1554220354.748197') # treat it as a long path to avoid path length issues on windows\n",
    "test_window_path_remote = dp.Path(r'/home/hsp252/nas_mount/hunter.ids.data/hunter.ids.preprocessor/processed_dataframes/angriff/2025-03-04_00-03-20_192.168.1.0-normal_DDoS_1/1556203726.876922-1556203756.876922')\n",
    "\n",
    "attack_data_set_path = dp.Path(r'/home/hsp252/nas_mount/hunter.ids.data/hunter.ids.preprocessor/processed_dataframes/angriff')\n",
    "ddos_test_path_parquet = dp.Path(r'/home/hsp252/Development/DDoS')\n",
    "\n",
    "feature_vectors = dp.pd.DataFrame()\n",
    "tsw_paths = dp.getThirtySecondWindowPaths(attack_data_set_path)\n",
    "NR_OF_FVS = 100\n",
    "\n",
    "# create ddos feature vectors\n",
    "# selected_cols = dp.pd.read_csv('/home/hsp252/nas_mount/hunter.ids.data/hunter.ids.preprocessor/processed_dataframes/angriff/2025-02-28_08-41-32_192.168.1.0-normal_backdoor/1556466432.434372-1556466462.434372/192.168.1.152/connections/1556466432.434372-1556466442.434372/96.0_192.168.1.193_49338.0_192.168.1.152_1880.0/host_data_chunk_full.csv').select_dtypes(include='number').columns.to_list() \\\n",
    "# + dp.pd.read_csv('/home/hsp252/nas_mount/hunter.ids.data/hunter.ids.preprocessor/processed_dataframes/angriff/2025-02-28_08-41-32_192.168.1.0-normal_backdoor/1556466432.434372-1556466462.434372/192.168.1.152/s2_selected_qs.csv').select_dtypes(include='number').columns.to_list() \\\n",
    "# + dp.pd.read_csv('/home/hsp252/nas_mount/hunter.ids.data/hunter.ids.preprocessor/processed_dataframes/angriff/2025-02-28_08-41-32_192.168.1.0-normal_backdoor/1556466432.434372-1556466462.434372/192.168.1.152/s3_connection_qs.csv').select_dtypes(include='number').columns.to_list() \\\n",
    "# + dp.pd.read_csv('/home/hsp252/nas_mount/hunter.ids.data/hunter.ids.preprocessor/processed_dataframes/angriff/2025-02-28_08-41-32_192.168.1.0-normal_backdoor/1556466432.434372-1556466462.434372/s1_general_qs.csv').select_dtypes(include='number').columns.to_list()\n",
    "\n",
    "# test_ddos_feature_vectors = dl.create_test_ddos_feature_vectors(ddos_test_path_parquet, selected_cols)\n",
    "\n",
    "# test_ddos_feature_vectors_path = dp.Path(r'/home/hsp252/Development/HSP_IDS/test_ddos_df.pkl')\n",
    "# dl.save_to_pickle(test_ddos_feature_vectors, test_ddos_feature_vectors_path)\n",
    "\n",
    "ddos_feature_vectors = dp.pp.load('test_ddos_df.pkl')\n",
    "valid_columns = ddos_feature_vectors.columns.to_list()\n",
    "ddos_feature_vectors['attack_type'] = 'ddos'\n",
    "feature_vectors = dp.pd.concat([feature_vectors, ddos_feature_vectors])\n",
    "print(ddos_feature_vectors.shape)\n",
    "\n",
    "# create mitm feature vectors and store\n",
    "runsomware_feature_vectors = dp.pd.DataFrame()\n",
    "for index, tsw_object in tsw_paths[tsw_paths['type'] == 'mitm'].iterrows():\n",
    "    start = dp.time.time()\n",
    "    tsw = dp.ThirtySecondWindow(dp.Path(tsw_object['path']))\n",
    "    mitm_local_feature_vectors = dl.create_feature_vectors(tsw, valid_columns)\n",
    "    mitm_local_feature_vectors['attack_type'] = tsw_object['type'] # add attack type column for training\n",
    "    runsomware_feature_vectors = dp.pd.concat([runsomware_feature_vectors, mitm_local_feature_vectors])\n",
    "    end = dp.time.time()\n",
    "    row_count = runsomware_feature_vectors.shape[0]\n",
    "    print(f\"created mitm feature vectors for {tsw_object['type']} in {end - start}s, rows: {row_count}\")\n",
    "    if row_count >= NR_OF_FVS:\n",
    "        break\n",
    "    #break\n",
    "feature_vectors = dp.pd.concat([feature_vectors, runsomware_feature_vectors])\n",
    "mitm_feature_vectors_path = dp.Path(r'/home/hsp252/Development/HSP_IDS/test_mitm_df.pkl')\n",
    "dl.save_to_pickle(runsomware_feature_vectors, mitm_feature_vectors_path)\n",
    "\n",
    "# create runsomware feature vectors and store\n",
    "runsomware_feature_vectors = dp.pd.DataFrame()\n",
    "for index, tsw_object in tsw_paths[tsw_paths['type'] == 'runsomware'].iterrows():\n",
    "    start = dp.time.time()\n",
    "    tsw = dp.ThirtySecondWindow(dp.Path(tsw_object['path']))\n",
    "    runsomware_local_feature_vectors = dl.create_feature_vectors(tsw, valid_columns)\n",
    "    runsomware_local_feature_vectors['attack_type'] = tsw_object['type'] # add attack type column for training\n",
    "    runsomware_feature_vectors = dp.pd.concat([runsomware_feature_vectors, runsomware_local_feature_vectors])\n",
    "    end = dp.time.time()\n",
    "    row_count = runsomware_feature_vectors.shape[0]\n",
    "    print(f\"created runsomware feature vectors for {tsw_object['type']} in {end - start}s, rows: {row_count}\")\n",
    "    if row_count >= NR_OF_FVS:\n",
    "        break\n",
    "    #break\n",
    "feature_vectors = dp.pd.concat([feature_vectors, runsomware_feature_vectors])\n",
    "runsomware_feature_vectors_path = dp.Path(r'/home/hsp252/Development/HSP_IDS/test_runsomware_df.pkl')\n",
    "dl.save_to_pickle(runsomware_feature_vectors, runsomware_feature_vectors_path)\n",
    "\n",
    "# create injection feature vectors and store\n",
    "injection_feature_vectors = dp.pd.DataFrame()\n",
    "for index, tsw_object in tsw_paths[tsw_paths['type'] == 'injection'].iterrows():\n",
    "    start = dp.time.time()\n",
    "    tsw = dp.ThirtySecondWindow(dp.Path(tsw_object['path']))\n",
    "    injection_local_feature_vectors = dl.create_feature_vectors(tsw, valid_columns)\n",
    "    injection_local_feature_vectors['attack_type'] = tsw_object['type'] # add attack type column for training\n",
    "    injection_feature_vectors = dp.pd.concat([injection_feature_vectors, injection_local_feature_vectors])\n",
    "    end = dp.time.time()\n",
    "    row_count = injection_feature_vectors.shape[0]\n",
    "    print(f\"created injection feature vectors for {tsw_object['type']} in {end - start}s, rows: {row_count}\")\n",
    "    if row_count >= NR_OF_FVS:\n",
    "        break\n",
    "    #break\n",
    "feature_vectors = dp.pd.concat([feature_vectors, injection_feature_vectors])\n",
    "injection_feature_vectors_path = dp.Path(r'/home/hsp252/Development/HSP_IDS/test_injection_df.pkl')\n",
    "dl.save_to_pickle(injection_feature_vectors, injection_feature_vectors_path)\n",
    "\n",
    "# create backdoor feature vectors and store\n",
    "backdoor_feature_vectors = dp.pd.DataFrame()\n",
    "for index, tsw_object in tsw_paths[tsw_paths['type'] == 'backdoor'].iterrows():\n",
    "    start = dp.time.time()\n",
    "    tsw = dp.ThirtySecondWindow(dp.Path(tsw_object['path']))\n",
    "    backdoor_local_feature_vectors = dl.create_feature_vectors(tsw, valid_columns)\n",
    "    backdoor_local_feature_vectors['attack_type'] = tsw_object['type'] # add attack type column for training\n",
    "    backdoor_feature_vectors = dp.pd.concat([backdoor_feature_vectors, backdoor_local_feature_vectors])\n",
    "    end = dp.time.time()\n",
    "    row_count = backdoor_feature_vectors.shape[0]\n",
    "    print(f\"created backdoorn feature vectors for {tsw_object['type']} in {end - start}s, rows: {row_count}\")\n",
    "    if row_count >= NR_OF_FVS:\n",
    "        break\n",
    "    #break\n",
    "feature_vectors = dp.pd.concat([feature_vectors, backdoor_feature_vectors])\n",
    "backdoor_feature_vectors_path = dp.Path(r'/home/hsp252/Development/HSP_IDS/test_backdoor_df.pkl')\n",
    "dl.save_to_pickle(backdoor_feature_vectors, backdoor_feature_vectors_path)\n",
    "\n",
    "# create dos feature vectors and store\n",
    "dos_feature_vectors = dp.pd.DataFrame()\n",
    "for index, tsw_object in tsw_paths[tsw_paths['type'] == 'dos'].iterrows():\n",
    "    start = dp.time.time()\n",
    "    tsw = dp.ThirtySecondWindow(dp.Path(tsw_object['path']))\n",
    "    dos_local_feature_vectors = dl.create_feature_vectors(tsw, valid_columns)\n",
    "    dos_local_feature_vectors['attack_type'] = tsw_object['type'] # add attack type column for training\n",
    "    dos_feature_vectors = dp.pd.concat([dos_feature_vectors, dos_local_feature_vectors])\n",
    "    end = dp.time.time()\n",
    "    row_count = dos_feature_vectors.shape[0]\n",
    "    print(f\"created dos feature vectors for {tsw_object['type']} in {end - start}s, rows: {row_count}\")\n",
    "    if row_count >= NR_OF_FVS:\n",
    "        break\n",
    "    #break\n",
    "feature_vectors = dp.pd.concat([feature_vectors, dos_feature_vectors])\n",
    "dos_feature_vectors_path = dp.Path(r'/home/hsp252/Development/HSP_IDS/test_dos_df.pkl')\n",
    "dl.save_to_pickle(dos_feature_vectors, dos_feature_vectors_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # put that into a dataset for RFC\n",
    "    # for non-DDoS stuff: acquire through 30s-windows, hosts and connections, do mean and median and add to dataset for training RFC\n",
    "    # check the least amount of 30s windows in attack classes and take this amount of 30s windows for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c65ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jannis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
